{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from tkinter.messagebox import showerror\n",
    "from tkinter.scrolledtext import ScrolledText\n",
    "from tkinter.ttk import Combobox\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score,accuracy_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def RNN():\n",
    "    max_words = 3500\n",
    "    max_len = 50\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.25)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy',recall_m,precision_m,f1_m])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self,model_name):\n",
    "        \"\"\"\n",
    "        model_name: \"SVM\", \"NB\" (Naive Bayes),\"KNN\", \"LSTM\", and \"pretrainedLSTM\"\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.TfidfVectorizer = None\n",
    "        self.Tokenizer = None\n",
    "        \n",
    "    def preprocess(self, input_path, mode, random_state=4, test_size=0.15):\n",
    "        \"\"\"\n",
    "        mode: \"train\" or \"predict\", if predict, data will not be splitted\n",
    "        \"\"\"\n",
    "        # Initialize dummy X,Y\n",
    "        X,Y = None, None\n",
    "\n",
    "        if self.model_name == \"LSTM\" or self.model_name == \"pretrainedLSTM\":\n",
    "            # Load data as a list of pairs of sentences and labels (0 for non-spam, 1 for spam)\n",
    "            data = []\n",
    "            if mode != \"predict_list\":\n",
    "                with open(input_path, encoding = 'utf-8') as f:\n",
    "                    for line in f:\n",
    "                        firstword = (line.split()[0])\n",
    "                        label = None\n",
    "                        if firstword == 'ham':\n",
    "                            label = 0\n",
    "                        else: \n",
    "                            label = 1\n",
    "                        text = line.replace(firstword,'').strip()\n",
    "                        data.append([text,label])\n",
    "            elif mode == \"predict_list\":\n",
    "                data = [[text,\"?\"] for text in input_path]\n",
    "\n",
    "            # transform data to numpy array\n",
    "            data = pd.DataFrame(np.array(data),columns=['text','label'])\n",
    "\n",
    "            # Dividing the dataset into features and lables\n",
    "            X = data['text']\n",
    "            Y = data['label']\n",
    "\n",
    "\n",
    "            # Tokenizer\n",
    "            max_len = 50\n",
    "            if mode == \"train\":\n",
    "                max_words = 3500\n",
    "                self.Tokenizer = Tokenizer(num_words=max_words)\n",
    "                self.Tokenizer.fit_on_texts(X)\n",
    "                X = self.Tokenizer.texts_to_sequences(X)\n",
    "                X = sequence.pad_sequences(X,maxlen=max_len)\n",
    "            else:\n",
    "                X = self.Tokenizer.texts_to_sequences(X)\n",
    "                X = sequence.pad_sequences(X,maxlen=max_len)\n",
    "\n",
    "\n",
    "\n",
    "        else: # Other models\n",
    "            # Load data as a list of pairs of sentences and labels (0 for non-spam, 1 for spam)\n",
    "            data = []\n",
    "            if mode != \"predict_list\":\n",
    "                with open(input_path, encoding = 'utf-8') as f:\n",
    "                    for line in f:\n",
    "                        firstword = (line.split()[0])\n",
    "                        label = None\n",
    "                        if firstword == 'ham':\n",
    "                            label = 0\n",
    "                        else: \n",
    "                            label = 1\n",
    "                        text = line.replace(firstword,'').strip()\n",
    "                        data.append([text,label])\n",
    "            elif mode == \"predict_list\":\n",
    "                data = [[text,\"?\"] for text in input_path]\n",
    "\n",
    "            # transform data to numpy array\n",
    "            data = np.array(data)\n",
    "            if (mode == \"train\"):\n",
    "\n",
    "                self.TfidfVectorizer = TfidfVectorizer()\n",
    "\n",
    "                # split data to X,Y\n",
    "                X = self.TfidfVectorizer.fit_transform(data[:,0]) #TFIDF transform for data\n",
    "                Y = data[:,1]    \n",
    "\n",
    "            elif (mode == \"predict\" or mode == \"predict_list\"):\n",
    "                X = self.TfidfVectorizer.transform(data[:,0]) #TFIDF transform for data\n",
    "                Y = data[:,1]   \n",
    "\n",
    "\n",
    "        # Split data into training and test set\n",
    "        if mode == \"train\":\n",
    "            X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=test_size,random_state=random_state)\n",
    "\n",
    "            # self.X_train, self.X_test, self.Y_train, self.Y_test = X_train,X_test,Y_train,Y_test\n",
    "\n",
    "            return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "        elif mode == \"predict\" or mode == \"predict_list\" :\n",
    "            return X\n",
    "\n",
    "    def train(self, input_path,test_size,random_state = 4):\n",
    "        \"\"\"\n",
    "        input_path: path to .txt file for training spam samples    \n",
    "        return: recall, precision, f_score\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Preprocess the dataaaaaa\n",
    "        X_train, X_test, Y_train, Y_test = self.preprocess(input_path, random_state = random_state, mode = \"train\", test_size = test_size)\n",
    "\n",
    "        #  Initial\n",
    "        if self.model_name == \"SVM\":\n",
    "            self.model = SVC(C=1e4)\n",
    "\n",
    "        elif self.model_name == \"KNN\":\n",
    "            self.model = KNeighborsClassifier(n_neighbors=1,metric='cosine')\n",
    "\n",
    "\n",
    "        elif self.model_name == \"Naive Bayes\":\n",
    "            self.model = model = MultinomialNB()\n",
    "\n",
    "\n",
    "        elif self.model_name == \"LSTM\":\n",
    "            self.model = RNN()\n",
    "\n",
    "        elif self.model_name == \"pretrainedLSTM\":\n",
    "            self.model = RNN()\n",
    "\n",
    "            self.model.load_weights('weights-9529-test-9615-best.h5')\n",
    "\n",
    "        # Training\n",
    "        if self.model_name != \"pretrainedLSTM\":\n",
    "            if self.model_name == \"LSTM\":\n",
    "                mdcp = ModelCheckpoint(filepath='best_weights_train.h5',monitor='val_f1_m',save_best_only=True)\n",
    "                self.model.fit(X_train,Y_train,batch_size=64,epochs=7, validation_split=0.2,callbacks=[mdcp])\n",
    "                self.model.load_weights('best_weights_train.h5') # Retrieve best weights\n",
    "            else:\n",
    "                self.model.fit(X_train,Y_train)\n",
    "\n",
    "        # Initialize metrics\n",
    "        recall, precision, f_score = None, None, None\n",
    "\n",
    "        # Evaluate\n",
    "        if self.model_name == \"LSTM\" or self.model_name == \"pretrainedLSTM\":\n",
    "            _,_,recall, precision, f_score = self.model.evaluate(X_test,Y_test,verbose=1)\n",
    "\n",
    "        elif self.model_name == \"Naive Bayes\":\n",
    "\n",
    "            Y_test_pred = (self.model.predict_proba(X_test.toarray())[:,1] > 0.25) # thresh = 0.25\n",
    "            f_score = f1_score(Y_test_pred.astype('uint8'),Y_test.astype('uint8'))\n",
    "            precision = precision_score(Y_test_pred.astype('uint8'),Y_test.astype('uint8'))\n",
    "            recall = recall_score(Y_test_pred.astype('uint8'),Y_test.astype('uint8'))\n",
    "        else:\n",
    "            Y_test_pred = self.model.predict(X_test)\n",
    "            f_score = f1_score(Y_test_pred.astype('uint8'),Y_test.astype('uint8'))\n",
    "            precision = precision_score(Y_test_pred.astype('uint8'),Y_test.astype('uint8'))\n",
    "            recall = recall_score(Y_test_pred.astype('uint8'),Y_test.astype('uint8'))\n",
    "\n",
    "        return recall, precision, f_score\n",
    "\n",
    "    def predict(self, input_path):\n",
    "        \"\"\"\n",
    "        input_path: path to .txt file for spam samples you want to predict (1 line 1 sample, \"?\"  for labels)\n",
    "        \"\"\"\n",
    "        # Preprocess the data\n",
    "        if isinstance(input_path, list):\n",
    "            X = self.preprocess(input_path, mode = 'predict_list')\n",
    "        else:\n",
    "            X = self.preprocess(input_path, mode = \"predict\")\n",
    "        if self.model_name == \"Naive Bayes\":\n",
    "            Y_pred = (self.model.predict_proba(X)[:,1] > 0.25)*1\n",
    "        elif self.model_name == \"pretrainedLSTM\" or self.model_name == \"LSTM\":\n",
    "            Y_pred = (self.model.predict(X) > 0.5)*1\n",
    "        else:\n",
    "            Y_pred = self.model.predict(X)\n",
    "\n",
    "        return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GUI(Frame):\n",
    "    def __init__(self):\n",
    "        Frame.__init__(self)\n",
    "        self.master.title('Spam detection v1.0')\n",
    "        self.master.geometry('440x510')\n",
    "        self.master.rowconfigure(3, weight=0)\n",
    "        self.master.columnconfigure(1, weight=0)\n",
    "        self.grid(sticky=W+E+N+S)\n",
    "        self.configure(background = 'lightgray')\n",
    "        self.master.configure(background = 'lightgray')\n",
    "        \n",
    "        #create and configure button [Sellect data]\n",
    "        self.browse = Button(self, text = 'Select data', command = self.load_data, width = 10)\n",
    "        self.browse.grid(row = 0, column = 0, pady = 20, padx = 30, ipadx = 20, ipady = 6, columnspan = 2, sticky = W)\n",
    "        \n",
    "        #create and configure selected file path output\n",
    "        self.path = Entry(self, disabledforeground = 'black')\n",
    "        self.path.grid(row = 0, column = 1, padx = 15, ipadx = 56, ipady = 8, columnspan = 3, sticky = W)\n",
    "        self.path.insert(0, 'No data selected') #init default text\n",
    "        self.path.configure(state = 'disabled') #not allow changes\n",
    "        \n",
    "        #create and configure model combobox\n",
    "        self.method = Combobox(self, value = [\"SVM\", \"Naive Bayes\", \"KNN\", \"LSTM\", \"pretrainedLSTM\"])\n",
    "        self.method.current(0)   #init default value to SVM\n",
    "        self.method.grid(row = 1, column = 0, padx = 30, ipadx = 43, ipady = 8, columnspan = 2, sticky = W)\n",
    "        \n",
    "        #create and configure input splitting ratio\n",
    "        self.splitting_rate = Entry(self, width = 19, fg = 'gray')\n",
    "        self.splitting_rate.grid(row = 1, column = 2, ipady = 8, columnspan = 2, sticky = W)\n",
    "        self.splitting_rate.insert(0, 'Splitting ratio (%)')               #init default text\n",
    "        self.splitting_rate.bind('<FocusIn>', self.onfocus_splitting)      #on focus on entry\n",
    "        self.splitting_rate.bind('<FocusOut>', self.outfocus_splitting)    #off focus on entry\n",
    "                \n",
    "        #create and configure input space\n",
    "        self.entry = ScrolledText(self, width = 15, height = 2, fg = 'gray')\n",
    "        self.entry.grid(row = 2, column = 0, padx = 30, pady = 20, ipady = 40, ipadx = 125, columnspan = 3, sticky = W)\n",
    "        self.entry.insert(INSERT, 'Insert query here and/or through file.')#init defalut text\n",
    "        self.entry.bind('<FocusIn>', self.onfocus_entry)                   #on focus on entry\n",
    "        self.entry.bind('<FocusOut>', self.outfocus_entry)                 #off focus on entry\n",
    "        \n",
    "        #input space is empty\n",
    "        self.entry_changed = False\n",
    "        \n",
    "        #create and configure button [Select query]\n",
    "        self.query_butt = Button(self, text = 'Select query', command = self.load_sample, width = 10)\n",
    "        self.query_butt.grid(row = 3, column = 0, padx = 30, pady = 10, ipady = 6, sticky = W)\n",
    "        \n",
    "        #create and configure button [Start]\n",
    "        self.start_butt = Button(self, text = 'Start', command = self.run, width = 10)\n",
    "        self.start_butt.grid(row = 3, column = 1, padx = 20, ipady = 6)\n",
    "\n",
    "        #create and configure button [Clear]\n",
    "        self.clear_butt = Button(self, text = 'Clear', command = self.clear, width = 10)\n",
    "        self.clear_butt.grid(row = 3, column = 2, padx = 37, pady = 5, ipady = 6, sticky = W)\n",
    "        \n",
    "        #create and configure output space\n",
    "        self.output = ScrolledText(self, state = 'disabled', width = 15, height = 2)\n",
    "        self.output.grid(row = 4, column = 0, padx = 30, pady = 10, ipady = 40, ipadx = 125, columnspan = 3, sticky = W)\n",
    "        \n",
    "    def onfocus_splitting(self, event = None):\n",
    "        #if there is no input yet when on focus\n",
    "        if self.splitting_rate.get() == 'Splitting ratio (%)':\n",
    "            self.splitting_rate.configure(fg = 'black')   #font color to black\n",
    "            self.splitting_rate.delete(0, END)            #delete default text\n",
    "\n",
    "    def outfocus_splitting(self, event = None):\n",
    "        #if there is no input when out of focus\n",
    "        if not self.splitting_rate.get():\n",
    "            self.splitting_rate.configure(fg = 'gray')    #font color to gray\n",
    "            self.splitting_rate.insert(0, 'Splitting ratio (%)')  #init default value again\n",
    "            \n",
    "    def onfocus_entry(self, event = None):\n",
    "        #if there is no input yet when on focus\n",
    "        if self.entry.get('1.0', END)[:-1] == 'Insert query here and/or through file.':\n",
    "            self.entry.configure(fg = 'black')    #font color to black\n",
    "            self.entry.delete('1.0', END)         #delete default text\n",
    "            self.entry_changed = True             #input has been changed\n",
    "\n",
    "    def outfocus_entry(self, event = None):\n",
    "        #if there is no input when out of focus\n",
    "        if not len(self.entry.get('1.0', END)[:-1]):\n",
    "            self.entry.configure(fg = 'gray')     #font color to gray\n",
    "            self.entry.insert(INSERT, 'Insert query here and/or through file.')   #init default value again\n",
    "            self.entry_changed = False     #input has not been changed or empty\n",
    "    \n",
    "    def run(self):\n",
    "        #take variable\n",
    "        model = self.method.get()\n",
    "        path = self.path.get()\n",
    "        query = self.entry.get(\"1.0\", END)\n",
    "        flag = 1\n",
    "        \n",
    "        #error check\n",
    "        try:\n",
    "            splitting_ratio = float(self.splitting_rate.get())\n",
    "        except ValueError:\n",
    "            messagebox.showerror(\"Error\", \"Splitting ratio must be a number.\")\n",
    "            flag = 0\n",
    "            \n",
    "        if splitting_ratio <= 0:\n",
    "            messagebox.showerror('Error', 'Splitting ratio must be larger than zero.')\n",
    "            flag = 0\n",
    "            \n",
    "        if path == 'No data selected':\n",
    "            messagebox.showerror('Error', 'No data selected.')\n",
    "            flag = 0\n",
    "            \n",
    "        if not len(query[:-1]):\n",
    "            messagebox.showerror('Error', 'Query is empty.')\n",
    "            flag = 0      \n",
    "        else:\n",
    "            query = query.split('\\n')[:-1]\n",
    "\n",
    "        try:\n",
    "            with open(path, 'r', encoding = 'utf-8') as f:\n",
    "                pass\n",
    "        except FileNotFoundError:\n",
    "            messagebox.showerror('Error', 'File not found.')\n",
    "            flag = 0\n",
    "\n",
    "        #executing\n",
    "        if flag:\n",
    "            #start output, make textbox editable\n",
    "            self.output.configure(state = 'normal')\n",
    "            self.output.insert(INSERT, 'Data from : ' + path + '\\n')\n",
    "            self.output.insert(INSERT, 'Model: ' + model + '\\n')\n",
    "            self.output.insert(INSERT, 'Splitting ratio : ' + str(splitting_ratio) + '%\\n\\n')\n",
    "            \n",
    "            #training model\n",
    "            myTrainer = Trainer(model)\n",
    "            recall, precision, f_score = myTrainer.train(path,test_size = splitting_ratio / 100)\n",
    "            self.output.insert(INSERT, f'recall: {recall}\\nprecision: {precision}\\nf score: {f_score}\\n\\n')\n",
    "            \n",
    "            #predict query\n",
    "            result = myTrainer.predict(query)\n",
    "            for i in range(len(query)):\n",
    "                self.output.insert(INSERT, query[i] + '\\nPrediction: ' + ('Spam\\n\\n' if int(result[i]) else 'Ham\\n\\n'))\n",
    "            \n",
    "            #end output, return textbox state to uneditable\n",
    "            self.output.configure(state = 'disabled')\n",
    "        \n",
    "        \n",
    "    def load_data(self):\n",
    "        fname = askopenfilename()   #open file\n",
    "        if fname:  #if file name is not empty\n",
    "            try:\n",
    "                self.path.configure(state = 'normal')   #change file path output to editable\n",
    "                self.path.delete(0, END)                #delete default text\n",
    "                self.path.insert(0, fname)              #insert file path\n",
    "                self.path.configure(state = 'disabled') #return file path to unediatble\n",
    "            except:\n",
    "                messagebox.showerror('Error', 'File not found.') \n",
    "\n",
    "    def load_sample(self):\n",
    "        fname = askopenfilename()  #open file\n",
    "        if fname:  #if file name is not empty\n",
    "            try:\n",
    "                with open(fname, 'r', encoding = 'utf-8') as f:  #open file\n",
    "                    query = f.read()\n",
    "                sample = self.entry.get('1.0', END)  #get existing input\n",
    "                if self.entry_changed:               #if there's existing input\n",
    "                    query = sample + query           #append input to query\n",
    "                self.entry.configure(fg = 'black')   #font to black\n",
    "                self.entry.delete('1.0', END)        #delete default text or existing input\n",
    "                self.entry.insert(INSERT, query)     #insert query to input\n",
    "            except:\n",
    "                showerror('Error', 'File not found.') \n",
    "\n",
    "    def clear(self):\n",
    "        self.output.configure(state = 'normal')   #change output to editable\n",
    "        self.output.delete('1.0', END)            #delete all of output\n",
    "        self.output.configure(state = 'disabled') #change output to unediatble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app = GUI()\n",
    "    app.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
